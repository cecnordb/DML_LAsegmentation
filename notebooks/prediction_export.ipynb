{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/albin/skolarbete/DML_LAsegmentation\n"
     ]
    }
   ],
   "source": [
    "%cd \"/home/albin/skolarbete/DML_LAsegmentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.train import patched_forward\n",
    "from models.unet import UNet3D, NormalizationType\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from monai.networks.nets import UNETR, SwinUNETR\n",
    "from scripts.dataset import TestDataset\n",
    "import SimpleITK as sitk\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "custom_palette = [\"#D32F2F\", \"#1976D2\", \"#4CAF50\"]  # Red, Blue, Light Green\n",
    "sns.set_palette(custom_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_path = 'data/Task02_Heart/imagesVl'\n",
    "val_label_path = 'data/Task02_Heart/labelsVl'\n",
    "\n",
    "patch_size = (64, 128, 128)\n",
    "val_dataset = TestDataset(val_image_path, val_label_path, scale_intensity=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albin/miniconda3/envs/dml/lib/python3.11/site-packages/monai/utils/deprecate_utils.py:221: FutureWarning: monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "# Load UNet3D model results\n",
    "file_name_unet3d = 'unet_model_results.pkl'\n",
    "with open(file_name_unet3d, 'rb') as f:\n",
    "    data_unet3d = pickle.load(f)\n",
    "    best_model_unet3d = UNet3D(in_channels=1, out_channels=1, features=[32, 64, 128, 256], normalization=NormalizationType.GROUP_NORM)\n",
    "    best_model_unet3d.load_state_dict(data_unet3d['model_state'])\n",
    "    results_unet3d = (best_model_unet3d, data_unet3d['train_metrics'], data_unet3d['val_metrics'])\n",
    "\n",
    "best_model_unet3d, results_train_unet3d, results_val_unet3d = results_unet3d\n",
    "\n",
    "# Load UNETR model results\n",
    "file_name_unetr = 'unetR_model_results.pkl'\n",
    "with open(file_name_unetr, 'rb') as f:\n",
    "    data_unetr = pickle.load(f)\n",
    "    best_model_unetr = UNETR(in_channels=1, out_channels=1, img_size=(64, 128, 128))\n",
    "    best_model_unetr.load_state_dict(data_unetr['model_state'])\n",
    "    results_unetr = (best_model_unetr, data_unetr['train_metrics'], data_unetr['val_metrics'])\n",
    "\n",
    "best_model_unetr, results_train_unetr, results_val_unetr = results_unetr\n",
    "\n",
    "# Load SwinUNETR model results\n",
    "file_name_swinunetr = 'swinUnetR_model_results.pkl'\n",
    "with open(file_name_swinunetr, 'rb') as f:\n",
    "    data_swinunetr = pickle.load(f)\n",
    "    best_model_swinunetr = SwinUNETR(in_channels=1, out_channels=1, img_size=(64, 128, 128))\n",
    "    best_model_swinunetr.load_state_dict(data_swinunetr['model_state'])\n",
    "    results_swinunetr = (best_model_swinunetr, data_swinunetr['train_metrics'], data_swinunetr['val_metrics'])\n",
    "\n",
    "best_model_swinunetr, results_train_swinunetr, results_val_swinunetr = results_swinunetr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = 'data/Task02_Heart/imagesVl'\n",
    "test_label_path = 'data/Task02_Heart/labelsVl'\n",
    "\n",
    "device = 'cuda'\n",
    "test_dataset = TestDataset(test_image_path, test_label_path, scale_intensity=True)\n",
    "image_idx = test_dataset.data_paths.index('data/Task02_Heart/imagesVl/la_030.nii')\n",
    "image, label = test_dataset[image_idx]\n",
    "image = image.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albin/miniconda3/envs/dml/lib/python3.11/site-packages/torch/_tensor.py:1443: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:84.)\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "image = image.to(device)\n",
    "best_model_unet3d = best_model_unet3d.to(device)\n",
    "best_model_unetr = best_model_unetr.to(device)\n",
    "best_model_swinunetr = best_model_swinunetr.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_unet = patched_forward(best_model_unet3d, image, patch_size, overlap=0.5, device=device).cpu()\n",
    "    pred_unetr = patched_forward(best_model_unetr, image, patch_size, overlap=0.5, device=device).cpu()\n",
    "    pred_swinunetr = patched_forward(best_model_swinunetr, image, patch_size, overlap=0.5, device=device).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_unet_sigmoid = torch.sigmoid(pred_unet).squeeze().numpy()\n",
    "pred_unetr_sigmoid = torch.sigmoid(pred_unetr).squeeze().numpy()\n",
    "pred_swinunetr_sigmoid = torch.sigmoid(pred_swinunetr).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply threshold to make the arrays binary\n",
    "pred_unet_sigmoid_binary = (pred_unet_sigmoid > 0.5).astype(int)\n",
    "pred_unetr_sigmoid_binary = (pred_unetr_sigmoid > 0.5).astype(int)\n",
    "pred_swinunetr_sigmoid_binary = (pred_swinunetr_sigmoid > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save tensor as .nii.gz with metadata from a reference file\n",
    "def save_tensor_as_nii_with_metadata(array, filename, reference_file):\n",
    "    # Load the reference image\n",
    "    reference_image = sitk.ReadImage(reference_file)\n",
    "    \n",
    "    # Create a new image with the provided array\n",
    "    new_image = sitk.GetImageFromArray(array)\n",
    "    \n",
    "    # Copy metadata from the reference image\n",
    "    new_image.CopyInformation(reference_image)\n",
    "    \n",
    "    # Save the new image\n",
    "    sitk.WriteImage(new_image, filename)\n",
    "\n",
    "# Save the predictions with metadata from the reference file\n",
    "reference_file = 'data/Task02_Heart/imagesVl/la_030.nii'\n",
    "save_tensor_as_nii_with_metadata(pred_unet_sigmoid_binary, r'./output/pred_unet_030.nii', reference_file)\n",
    "save_tensor_as_nii_with_metadata(pred_unetr_sigmoid_binary, r'./output/pred_unetr_030.nii', reference_file)\n",
    "save_tensor_as_nii_with_metadata(pred_swinunetr_sigmoid_binary, r'./output/pred_swinunetr_030.nii', reference_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
