{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"/home/albin/skolarbete/DML_LAsegmentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.train import train, validate, patched_forward\n",
    "from scripts.utils import CombinedLoss\n",
    "from models.unet import UNet3D\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from monai.networks.nets import UNETR\n",
    "\n",
    "from scripts.dataset import TrainDataset, TestDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = 'data/Task02_Heart/imagesTr'\n",
    "train_label_path = 'data/Task02_Heart/labelsTr'\n",
    "val_image_path = 'data/Task02_Heart/imagesVl'\n",
    "val_label_path = 'data/Task02_Heart/labelsVl'\n",
    "\n",
    "patch_size = (64, 64, 64)\n",
    "train_dataset = TrainDataset(train_image_path, train_label_path, patch_size, require_target=0.5, preload_all_images=True, num_patches_per_image=2)\n",
    "val_dataset = TestDataset(val_image_path, val_label_path)\n",
    "\n",
    "batch_size = 8\n",
    "# The effective batch size will be batch_size * num_patches_per_image\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNETR(in_channels=1, out_channels=1, img_size=(64 , 64 , 64))\n",
    "\n",
    "loss_fn = CombinedLoss(smooth=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epochs = 500\n",
    "validation_freq = 100\n",
    "\n",
    "results = train(model, optimizer, loss_fn, train_loader, val_loader, None, device, epochs, patch_size=patch_size, validation_freq=validation_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'unetR_model_results.pkl'\n",
    "\n",
    "# Check if 'results' exists in the local scope\n",
    "if 'results' in locals():\n",
    "    # Unpack and save the model's state dict and results\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'model_state': results[0].state_dict(),  # best_model state dict\n",
    "            'train_metrics': results[1],  # results_train\n",
    "            'val_metrics': results[2]    # results_val\n",
    "        }, f)\n",
    "    print(f\"Results and model saved to {file_name}\")\n",
    "\n",
    "else:\n",
    "    # Load the results and model state from the file\n",
    "    with open(file_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        best_model = UNETR(in_channels=1, out_channels=1, img_size=(64 , 64 , 64))\n",
    "\n",
    "        best_model.load_state_dict(data['model_state'])\n",
    "        results = (best_model, data['train_metrics'], data['val_metrics'])\n",
    "    print(f\"Results and model loaded from {file_name}\")\n",
    "\n",
    "best_model, results_train, results_val = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for easier plotting with Seaborn\n",
    "df_train_loss = pd.DataFrame({'Epoch': range(len(results_train['loss'])), 'Value': results_train['loss'], 'Metric': 'Loss', 'Type': 'Train'})\n",
    "df_val_loss = pd.DataFrame({'Epoch': [validation_freq * (1 + x) for x in range(len(results_val['loss']))], 'Value': results_val['loss'], 'Metric': 'Loss', 'Type': 'Validation'})\n",
    "\n",
    "df_train_dice = pd.DataFrame({'Epoch': range(len(results_train['dice'])), 'Value': results_train['dice'], 'Metric': 'Dice', 'Type': 'Train'})\n",
    "df_val_dice = pd.DataFrame({'Epoch': [validation_freq * (1 + x) for x in range(len(results_val['dice']))], 'Value': results_val['dice'], 'Metric': 'Dice', 'Type': 'Validation'})\n",
    "\n",
    "df_train_iou = pd.DataFrame({'Epoch': range(len(results_train['iou'])), 'Value': results_train['iou'], 'Metric': 'IoU', 'Type': 'Train'})\n",
    "df_val_iou = pd.DataFrame({'Epoch': [validation_freq * (1 + x) for x in range(len(results_val['iou']))], 'Value': results_val['iou'], 'Metric': 'IoU', 'Type': 'Validation'})\n",
    "\n",
    "# Combine the DataFrames\n",
    "df = pd.concat([df_train_loss, df_val_loss, df_train_dice, df_val_dice, df_train_iou, df_val_iou])\n",
    "\n",
    "# Plot using Seaborn\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "sns.lineplot(data=df[df['Metric'] == 'Loss'], x='Epoch', y='Value', hue='Type', ax=axs[0])\n",
    "axs[0].set_title('Training and Validation Loss')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Loss')\n",
    "\n",
    "sns.lineplot(data=df[df['Metric'] == 'Dice'], x='Epoch', y='Value', hue='Type', ax=axs[1])\n",
    "axs[1].set_title('Training and Validation Dice')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Dice')\n",
    "\n",
    "sns.lineplot(data=df[df['Metric'] == 'IoU'], x='Epoch', y='Value', hue='Type', ax=axs[2])\n",
    "axs[2].set_title('Training and Validation IoU')\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].set_ylabel('IoU')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = val_dataset[0]\n",
    "image = image.unsqueeze(0)\n",
    "image = image.to(device)\n",
    "with torch.no_grad():\n",
    "    pred_logits = patched_forward(best_model, image, patch_size, 'cuda')\n",
    "pred = torch.sigmoid(pred_logits)\n",
    "pred = pred.squeeze(0, 1)\n",
    "image = image.squeeze(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the 50th slice along the first axis\n",
    "slice_index = 50\n",
    "\n",
    "image_slice = image[slice_index].cpu().numpy()\n",
    "pred_slice = pred[slice_index].cpu().numpy()\n",
    "label_slice = label[slice_index].cpu().numpy()\n",
    "\n",
    "# Create the figure and the axes with 3 subplots side by side\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot the original image slice\n",
    "axs[0].imshow(image_slice, cmap='gray')\n",
    "axs[0].set_title('Image Slice')\n",
    "axs[0].axis('off')\n",
    "\n",
    "# Plot the prediction slice\n",
    "axs[1].imshow(pred_slice, vmin=0, vmax=1, cmap='Reds')\n",
    "axs[1].set_title('Prediction Slice')\n",
    "axs[1].axis('off')\n",
    "\n",
    "# Plot the label slice\n",
    "axs[2].imshow(label_slice, cmap='Greens')\n",
    "axs[2].set_title('Label Slice')\n",
    "axs[2].axis('off')\n",
    "\n",
    "# Display the figure\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the 50th slice along the first axis\n",
    "slice_index = 50\n",
    "image_slice = image[slice_index].cpu().numpy()\n",
    "pred_slice = pred[slice_index].cpu().numpy()\n",
    "label_slice = label[slice_index].cpu().numpy()\n",
    "\n",
    "pred_slice = (pred_slice > 0.5).astype(np.float32)\n",
    "\n",
    "# Normalize image slice for visualization (if needed)\n",
    "image_slice = (image_slice - image_slice.min()) / (image_slice.max() - image_slice.min())\n",
    "\n",
    "# Create an RGB image from the grayscale slice\n",
    "image_rgb = np.stack([image_slice]*3, axis=-1)\n",
    "\n",
    "# Create solid colors for the prediction and label overlays\n",
    "red_overlay = np.zeros_like(image_rgb)\n",
    "red_overlay[..., 0] = 1  # Red color for prediction\n",
    "\n",
    "green_overlay = np.zeros_like(image_rgb)\n",
    "green_overlay[..., 1] = 1  # Green color for label\n",
    "\n",
    "# Create the prediction and label masks (expanding dims for compatibility)\n",
    "pred_mask = np.expand_dims(pred_slice, axis=-1)\n",
    "label_mask = np.expand_dims(label_slice, axis=-1)\n",
    "\n",
    "# Set the opacity for the overlays (50% opacity)\n",
    "opacity = 0.5\n",
    "\n",
    "# Blend the solid color with the original image using the mask\n",
    "# First, apply the red overlay for predictions\n",
    "overlay_image = image_rgb * (1 - pred_mask * opacity) + red_overlay * pred_mask * opacity\n",
    "\n",
    "# Then, apply the green overlay for labels\n",
    "overlay_image = overlay_image * (1 - label_mask * opacity) + green_overlay * label_mask * opacity\n",
    "\n",
    "# Plot the resulting image with the 50% opacity overlays\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(overlay_image)\n",
    "plt.title('Image with 50% Opacity Prediction and Label Overlays')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
